"""TEST FILES GENERATED BY GPT"""

# tests/test_live_scrape.py
import os
import json
import pytest
import re
from urllib.parse import urlparse


LIVE = os.getenv("LIVE_SCRAPE", "").strip() == "1"
pytestmark = pytest.mark.skipif(
    not LIVE, reason="Set LIVE_SCRAPE=1 to enable live web tests against thegradcafe.com"
)

BASE = "https://www.thegradcafe.com/survey/"

MONTH_RE = re.compile(
    r"\b(January|February|March|April|May|June|July|August|September|October|November|December)\b"
)
STATUS_SET = {"Accepted", "Rejected", "Interview", "Waitlisted", "Pending"}
DEGREE_SET = {"Masters", "PhD", "MFA", "MBA", "JD", "EdD", "Other", "PsyD"}


def test_live_fetch_and_parse_page_shape_and_values():
    from scrape import Scraper

    s = Scraper(BASE, delay=0.0)
    url = s._build_page_url(1)
    html = s._fetch_page(url)
    assert html, "Expected non-empty HTML from live site"

    rows = s._parse_page(html, url)
    assert isinstance(rows, list) and len(rows) > 0

    expected_keys = {
        "program", "university", "date_added", "url", "status",
        "comments", "accept_date", "reject_date", "start_term", "start_year",
        "citizenship", "gre_total", "gre_verbal", "gre_aw", "degree", "gpa",
    }

    seen_urls = set()
    for r in rows:
        # exact schema
        assert set(r.keys()) == expected_keys

        # SHALL fields: non-empty strings
        for k in ("program", "university", "date_added", "url", "status"):
            assert isinstance(r[k], str) and r[k].strip()

        # date_added looks like a month name date (page shows human format)
        assert MONTH_RE.search(r["date_added"])

        # status is canonical
        assert r["status"] in STATUS_SET

        # absolute URL, gradcafe domain, entry path (/survey or /result)
        u = urlparse(r["url"])
        assert u.scheme in ("http", "https")
        assert u.netloc.endswith("thegradcafe.com")
        assert re.search(r"/(survey|result)/", u.path), f"Unexpected entry path: {u.path}"

        # degree either allowed or None
        assert (r["degree"] is None) or (r["degree"] in DEGREE_SET)

        # Optional types
        for numk in ("gre_total", "gre_verbal"):
            assert (r[numk] is None) or isinstance(r[numk], int)
        for floatk in ("gre_aw", "gpa"):
            assert (r[floatk] is None) or isinstance(r[floatk], float)
        for optk in ("comments", "accept_date", "reject_date", "start_term", "citizenship"):
            assert (r[optk] is None) or isinstance(r[optk], str)
        assert (r["start_year"] is None) or isinstance(r["start_year"], int)

        # no duplicates within the same page
        assert r["url"] not in seen_urls
        seen_urls.add(r["url"])


def test_live_fetch_and_parse_basic():
    from scrape import Scraper

    s = Scraper(BASE, delay=0.0)
    url = s._build_page_url(1)
    html = s._fetch_page(url)
    rows = s._parse_page(html, url)

    assert isinstance(rows, list) and len(rows) > 0
    for r in rows[:5]:
        for k in ("program", "university", "date_added", "url", "status"):
            assert k in r and isinstance(r[k], str) and r[k].strip()
        assert r["status"] in STATUS_SET


def test_live_scrape_one_page_and_save(tmp_path):
    from scrape import Scraper

    s = Scraper(BASE, delay=0.0)
    out = tmp_path / "data" / "applicant_data.json"

    rows = s.scrape(start_page=1, max_pages=1, out_path=str(out))
    assert isinstance(rows, list) and len(rows) > 0
    assert out.exists()

    data = json.loads(out.read_text(encoding="utf-8"))
    assert isinstance(data, list) and len(data) == len(rows)

    # Spot-check first rowâ€™s SHALL fields
    r = data[0]
    for k in ("program", "university", "date_added", "url", "status"):
        assert k in r and isinstance(r[k], str) and r[k].strip()
